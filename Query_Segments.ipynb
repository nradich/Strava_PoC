{"cells":[{"cell_type":"markdown","metadata":{},"source":["Run the config file to authenticate script and query Key Vault\n","\n","Second script. Run after 'Query_Activites'"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/plain":["#to see if scope is there\n","\n","#dbutils.secrets.listScopes()\n","client_id = dbutils.secrets.get(scope = \"key_vault_secrets\", key = \"clientid\") \n","\n","client_secret = dbutils.secrets.get(scope = \"key_vault_secrets\", key = \"clientsecret\") \n","\n","new_refresh_token = dbutils.secrets.get(scope = \"key_vault_secrets\", key = \"newrefreshtoken\")\n","\n","activity_id_path = dbutils.secrets.get(scope = \"key_vault_secrets\", key = \"activityidpath\") \n","\n","historical_activity_id_path = dbutils.secrets.get(scope = \"key_vault_secrets\", key = \"historicalactivitydfpath\") \n","\n","segment_effort_path = dbutils.secrets.get(scope = \"key_vault_secrets\", key = \"segmenteffortpath\") \n","\n","import requests\n","\n","import urllib3\n","\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","\n","\n","auth_url = \"https://www.strava.com/oauth/token\"\n","\n","activites_url = \"https://www.strava.com/api/v3/athlete/activities\"\n","\n","\n","\n","\n","\n","payload = {\n","\n","    'client_id':  client_id,\n","\n","    'client_secret': client_secret,\n","\n","    'refresh_token': new_refresh_token,\n","\n","    'grant_type': 'refresh_token',\n","\n","    'f': 'json'\n","\n","}\n","\n","\n","\n","res = requests.post(auth_url, data=payload, verify=False)\n","\n","access_token = res.json()['access_token']\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[]}],"source":["%run config"]},{"cell_type":"markdown","metadata":{},"source":["Dependencies "]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[]}],"source":["from pyspark.sql.functions import * \n","import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["### API Query to get more specific details for each activity, need to pass each activity off individually "]},{"cell_type":"markdown","metadata":{},"source":["Get full activity dataset from what is written in storage, should be all activites"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[]}],"source":["\n","full_activity_dataset = spark.read.format(\"delta\").load(historical_activity_id_path)"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/plain":["+------------+--------------------+-------------------+--------+-----------+------------+----------+--------------------+--------------------+--------------------+\n","|activity_ids|          start_date|      activity_name|distance|moving_time|elapsed_time|sport_type|total_elevation_gain|    ingest_file_name|         ingested_at|\n","+------------+--------------------+-------------------+--------+-----------+------------+----------+--------------------+--------------------+--------------------+\n","|  7480841356|2022-07-16T22:26:16Z|          city wide| 32228.3|       5488|        6756|      Ride|               375.5|activity_information|2022-09-19 21:37:...|\n","|  7454211244|2022-07-12T01:28:02Z|       straight up |  1710.1|       1297|        1315|      Walk|               142.8|activity_information|2022-09-19 21:37:...|\n","|  7437771392|2022-07-09T00:06:28Z|        friday ride| 23022.7|       4455|        5896|      Ride|               296.4|activity_information|2022-09-19 21:37:...|\n","|  7411376407|2022-07-03T18:22:32Z|butte lookout trail|  6313.4|       5731|       10037|      Hike|               466.2|activity_information|2022-09-19 21:37:...|\n","|  7405131726|2022-07-02T17:38:50Z|          wild plum|  8823.0|       8127|       13070|      Hike|               332.1|activity_information|2022-09-19 21:37:...|\n","|  7399680604|2022-07-01T17:31:12Z|          deer lake| 10899.6|       8996|       13271|      Hike|               326.0|activity_information|2022-09-19 21:37:...|\n","|  7390526948|2022-06-30T00:36:40Z|        jog it out |  3973.8|       1331|        1355|       Run|                23.9|activity_information|2022-09-19 21:37:...|\n","|  7379581860|2022-06-28T00:45:35Z|     evening rumble| 16263.2|       2950|        3696|      Ride|               148.2|activity_information|2022-09-19 21:37:...|\n","|  7358811380|2022-06-23T23:59:45Z|     evening rumble| 20892.4|       4019|        5765|      Ride|               238.4|activity_information|2022-09-19 21:37:...|\n","|  7303733207|2022-06-13T19:27:44Z|          lunch jog|  3033.2|        929|         933|       Run|                16.2|activity_information|2022-09-19 21:37:...|\n","|  7261304130|2022-06-05T18:29:30Z|   cowles mountain |  4726.1|       4206|        5639|      Hike|               274.0|activity_information|2022-09-19 21:37:...|\n","|  7815243449|2022-09-16T00:46:49Z|        evening jog|  4801.8|       1621|        1632|       Run|                36.5|activity_information|2022-09-19 21:37:...|\n","|  7793305043|2022-09-11T19:07:35Z|       sunday ride | 17203.2|       3694|        5263|      Ride|               142.0|activity_information|2022-09-19 21:37:...|\n","|  7749592368|2022-09-03T14:29:59Z|         loch vale |  8699.4|       8513|       21499|      Hike|               343.0|activity_information|2022-09-19 21:37:...|\n","|  7743374567|2022-09-02T16:31:15Z|         7 bridges |  5178.6|       5082|        5346|      Hike|               199.8|activity_information|2022-09-19 21:37:...|\n","|  7728807247|2022-08-31T01:46:13Z|        evening jog|  4315.0|       1494|        1494|       Run|                38.1|activity_information|2022-09-19 21:37:...|\n","|  7701046541|2022-08-25T23:57:57Z|   thursday rumble | 18822.7|       3576|        5030|      Ride|               167.3|activity_information|2022-09-19 21:37:...|\n","|  7638869921|2022-08-14T17:52:04Z|       sunday ride | 20825.0|       4335|        6329|      Ride|               176.9|activity_information|2022-09-19 21:37:...|\n","|  7523741608|2022-07-25T00:02:35Z|        Sunday jog |  2816.6|        915|         920|       Run|                18.0|activity_information|2022-09-19 21:37:...|\n","|  7512286724|2022-07-22T22:37:51Z|     mount davidson|  5190.2|       4017|        4234|      Walk|               200.9|activity_information|2022-09-19 21:37:...|\n","+------------+--------------------+-------------------+--------+-----------+------------+----------+--------------------+--------------------+--------------------+\n","only showing top 20 rows"]},"metadata":{},"output_type":"display_data"}],"source":["full_activity_dataset.show()"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"data":{"text/plain":["+--------------------+\n","|         ingested_at|\n","+--------------------+\n","|2022-09-19 21:37:...|\n","|2022-11-14 22:29:...|\n","|2022-10-26 17:40:...|\n","|2022-10-17 17:59:...|\n","+--------------------+"]},"metadata":{},"output_type":"display_data"}],"source":["full_activity_dataset.select('ingested_at').distinct().show()"]},{"cell_type":"markdown","metadata":{},"source":["Ggrab all of the disinct activity IDs "]},{"cell_type":"code","execution_count":43,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"920f4af1-ce5f-48a7-8372-4725ed606ca0","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":[]}],"source":["full_activity_ids = full_activity_dataset.select('activity_ids').distinct().rdd.flatMap(lambda x: x).collect()"]},{"cell_type":"markdown","metadata":{},"source":["Take unique activity ids, and extract all of the segments associated with those activities"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[]}],"source":["def query_segments(activity_ids):\n","    \"\"\"Gets all segment_ids for each activity_id submitted\n","    Returns distinct values\"\"\"\n","    df = pd.DataFrame()\n","    activity_id_list =[]\n","    segment_id_list =[]\n","    for id in activity_ids:\n","        activity_id_urls = (\"{}{}?include_all_efforts= True\").format(\"https://www.strava.com/api/v3/activities/\",id)\n","        header = {'Authorization': 'Bearer ' + access_token}\n","        param = {'per_page': 200, 'page': 1}\n","        my_activity = requests.get(activity_id_urls, headers=header, params=param).json()\n","\n","        segment_effort_count =  len(my_activity['segment_efforts'])\n","        count = 0\n","        while count < segment_effort_count:\n","\n","            activity_id = my_activity['segment_efforts'][count]['activity']['id']\n","            segment_id = my_activity['segment_efforts'][count]['id']\n","            activity_id_list.append(activity_id)\n","            segment_id_list.append(segment_id)\n","                  \n","            columns = ['segment_id', 'activity_id']\n","            extracted_data = [segment_id_list, activity_id_list]\n","            segment_df = pd.DataFrame.from_dict(dict(zip(columns, extracted_data)))\n","\n","            df= df.append(segment_df)\n","            count += 1\n","\n","    #convert pandas df to spark\n","        \n","    segment_spark_df = spark.createDataFrame(df)\n","\n","    #drop duplicate entries\n","    segment_spark_df = segment_spark_df.dropDuplicates()\n","\n","    segment_spark_df = segment_spark_df.select(concat(segment_spark_df.segment_id,segment_spark_df.activity_id).alias(\"Activity_Segment_JointID\"), 'segment_id','activity_id')\n","\n","    segment_spark_df = segment_spark_df.withColumn(\"ingest_file_name\", lit(\"segment_efforts_ids\")) \\\n","                                .withColumn(\"ingested_at\", lit(current_timestamp()))\n","\n","    return segment_spark_df"]},{"cell_type":"markdown","metadata":{},"source":["Need to compare activites already stored with segments as there are limits for strava API\n","\n","Initially will go 99 request, but might need to reduce that to save requests for segments"]},{"cell_type":"markdown","metadata":{},"source":["Query all segments from all activities "]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[]}],"source":["full_activity_ids_order =  full_activity_ids.sort()"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"data":{"text/plain":["Out[22]: [3764074685,\n"," 3809768344,\n"," 3865986737,\n"," 3871052555,\n"," 3876332481,\n"," 4079983225,\n"," 4382047703,\n"," 4414021787,\n"," 4730507502,\n"," 4768097716,\n"," 4838912326,\n"," 4910436714,\n"," 4948214694,\n"," 4993537055,\n"," 5198781723,\n"," 5281545880,\n"," 5326544918,\n"," 5391043545,\n"," 5408255638,\n"," 5413547479,\n"," 5448078140,\n"," 5487914339,\n"," 5503770439,\n"," 5508615942,\n"," 5524575370,\n"," 5718648252,\n"," 5740260874,\n"," 5755543494,\n"," 5972584497,\n"," 5987842682,\n"," 5997390802,\n"," 6040654473,\n"," 6059385275,\n"," 6114231607,\n"," 6129061619,\n"," 6162281948,\n"," 6194864569,\n"," 6239126619,\n"," 6261731220,\n"," 6270833770,\n"," 6279812615,\n"," 6284670536,\n"," 6298941266,\n"," 6302328393,\n"," 6395162679,\n"," 6439530045,\n"," 6627964856,\n"," 6648045580,\n"," 6658996209,\n"," 6754060843,\n"," 6759396023,\n"," 6825624837,\n"," 6856368170,\n"," 6886523125,\n"," 6908050193,\n"," 6967425665,\n"," 6967590959,\n"," 6991844521,\n"," 6992488859,\n"," 7004837267,\n"," 7041321207,\n"," 7062090532,\n"," 7095425818,\n"," 7138047360,\n"," 7166250297,\n"," 7208614563,\n"," 7218381768,\n"," 7224011708,\n"," 7229384684,\n"," 7261304130,\n"," 7303733207,\n"," 7358811380,\n"," 7379581860,\n"," 7390526948,\n"," 7399680604,\n"," 7405131726,\n"," 7411376407,\n"," 7437771392,\n"," 7454211244,\n"," 7480841356,\n"," 7491632820,\n"," 7508021600,\n"," 7512286724,\n"," 7523741608,\n"," 7638869921,\n"," 7701046541,\n"," 7728807247,\n"," 7743374567,\n"," 7749592368,\n"," 7793305043,\n"," 7815243449,\n"," 7891754293,\n"," 7902311749,\n"," 7923494483,\n"," 7927809483,\n"," 7949407856,\n"," 7979752538,\n"," 7990337436,\n"," 8014745708,\n"," 8017675208,\n"," 8030070205,\n"," 8050118603,\n"," 8060407021]"]},"metadata":{},"output_type":"display_data"}],"source":["full_activity_ids"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"data":{"text/html":["<span class=\"ansi-red-fg\">IllegalArgumentException</span>: java.net.URISyntaxException: Illegal character in scheme name at index 0: [REDACTED]"]},"metadata":{},"output_type":"display_data"},{"ename":"Error","evalue":"---------------------------------------------------------------------------\nIllegalArgumentException                  Traceback (most recent call last)\n<command--1> in <module>\n----> 1 segments_in_storage = spark.read.format(\"delta\").load(segment_effort_path)\n\n/databricks/spark/python/pyspark/sql/readwriter.py in load(self, path, format, schema, **options)\n    156         self.options(**options)\n    157         if isinstance(path, str):\n--> 158             return self._df(self._jreader.load(path))\n    159         elif path is not None:\n    160             if type(path) != list:\n\n/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py in __call__(self, *args)\n   1302 \n   1303         answer = self.gateway_client.send_command(command)\n-> 1304         return_value = get_return_value(\n   1305             answer, self.gateway_client, self.target_id, self.name)\n   1306 \n\n/databricks/spark/python/pyspark/sql/utils.py in deco(*a, **kw)\n    121                 # Hide where the exception came from that shows a non-Pythonic\n    122                 # JVM exception message.\n--> 123                 raise converted from None\n    124             else:\n    125                 raise\n\nIllegalArgumentException: java.net.URISyntaxException: Illegal character in scheme name at index 0: [REDACTED]","output_type":"error","traceback":["Error: ---------------------------------------------------------------------------\n","IllegalArgumentException                  Traceback (most recent call last)\n","<command--1> in <module>\n","----> 1 segments_in_storage = spark.read.format(\"delta\").load(segment_effort_path)\n","\n","/databricks/spark/python/pyspark/sql/readwriter.py in load(self, path, format, schema, **options)\n","    156         self.options(**options)\n","    157         if isinstance(path, str):\n","--> 158             return self._df(self._jreader.load(path))\n","    159         elif path is not None:\n","    160             if type(path) != list:\n","\n","/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py in __call__(self, *args)\n","   1302 \n","   1303         answer = self.gateway_client.send_command(command)\n","-> 1304         return_value = get_return_value(\n","   1305             answer, self.gateway_client, self.target_id, self.name)\n","   1306 \n","\n","/databricks/spark/python/pyspark/sql/utils.py in deco(*a, **kw)\n","    121                 # Hide where the exception came from that shows a non-Pythonic\n","    122                 # JVM exception message.\n","--> 123                 raise converted from None\n","    124             else:\n","    125                 raise\n","\n","IllegalArgumentException: java.net.URISyntaxException: Illegal character in scheme name at index 0: [REDACTED]\n","\tat l._doExecution (c:\\Users\\nicholas.radich\\.vscode\\extensions\\paiqo.databricks-vscode-1.2.3\\dist\\node\\extension.js:2:57244)\n","\tat process.processTicksAndRejections (node:internal/process/task_queues:96:5)\n","\tat async l.executeHandler (c:\\Users\\nicholas.radich\\.vscode\\extensions\\paiqo.databricks-vscode-1.2.3\\dist\\node\\extension.js:2:52643)\n","\tat async m.$executeCells (c:\\Users\\nicholas.radich\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\workbench\\api\\node\\extensionHostProcess.js:94:107639)"]}],"source":["try:\n","    #Query path, see if there are any activities with their associated segments written to storage\n","    segments_in_storage = spark.read.format(\"delta\").load(segment_effort_path)\n","except:\n","    #if that errors, meaning first time running the script\n","    #Write the first 99 activites to storage, will need to specificy sort order \n","    top_99_activity_ids = \n","    write_dataframe_to_storage(historical_df_to_write,storagepath, \"mergeSchema\", \"append\" )\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/html":["<span class=\"ansi-red-fg\">NameError</span>: name &#39;segment_id_df&#39; is not defined"]},"metadata":{},"output_type":"display_data"},{"ename":"Error","evalue":"---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\n<command--1> in <module>\n----> 1 segment_id_df.show()\n\nNameError: name 'segment_id_df' is not defined","output_type":"error","traceback":["Error: ---------------------------------------------------------------------------\n","NameError                                 Traceback (most recent call last)\n","<command--1> in <module>\n","----> 1 segment_id_df.show()\n","\n","NameError: name 'segment_id_df' is not defined\n","\tat l._doExecution (c:\\Users\\nicholas.radich\\.vscode\\extensions\\paiqo.databricks-vscode-1.2.3\\dist\\node\\extension.js:2:57244)\n","\tat process.processTicksAndRejections (node:internal/process/task_queues:96:5)\n","\tat async l.executeHandler (c:\\Users\\nicholas.radich\\.vscode\\extensions\\paiqo.databricks-vscode-1.2.3\\dist\\node\\extension.js:2:52643)\n","\tat async m.$executeCells (c:\\Users\\nicholas.radich\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\workbench\\api\\node\\extensionHostProcess.js:94:107639)"]}],"source":["segment_id_df.show()"]},{"cell_type":"markdown","metadata":{},"source":["Need to limit to 100 request as the api throws an errors after"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/html":["<span class=\"ansi-red-fg\">KeyError</span>: &#39;segment_efforts&#39;"]},"metadata":{},"output_type":"display_data"},{"ename":"Error","evalue":"---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\n<command--1> in <module>\n----> 1 segment_id_df = query_segments(full_activity_ids)\n\n<command--1> in query_segments(activity_ids)\n\nKeyError: 'segment_efforts'","output_type":"error","traceback":["Error: ---------------------------------------------------------------------------\n","KeyError                                  Traceback (most recent call last)\n","<command--1> in <module>\n","----> 1 segment_id_df = query_segments(full_activity_ids)\n","\n","<command--1> in query_segments(activity_ids)\n","\n","KeyError: 'segment_efforts'\n","\tat l._doExecution (c:\\Users\\nicholas.radich\\.vscode\\extensions\\paiqo.databricks-vscode-1.2.3\\dist\\node\\extension.js:2:57244)\n","\tat process.processTicksAndRejections (node:internal/process/task_queues:96:5)\n","\tat async l.executeHandler (c:\\Users\\nicholas.radich\\.vscode\\extensions\\paiqo.databricks-vscode-1.2.3\\dist\\node\\extension.js:2:52643)\n","\tat async m.$executeCells (c:\\Users\\nicholas.radich\\AppData\\Local\\Programs\\Microsoft VS Code\\resources\\app\\out\\vs\\workbench\\api\\node\\extensionHostProcess.js:94:107639)"]}],"source":["segment_id_df = query_segments(full_activity_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["write_dataframe_to_storage(segment_id_df,segment_effort_path, \"overwriteSchema\",\"overwrite\" )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["segments_in_storage = spark.read.format(\"delta\").load(segment_effort_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#hopefull.groupBy('activity_id').agg(countDistinct('segment_id')).show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["activity_list = hopefull.select('activity_id').distinct().collect()\n","len(activity_list)\n","len(subset)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#need to get distinct activity_ids and run them through the segment\n","#we make 1 api query in the first script, so gonna be allowed 99 with this run "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#get all of the activity_ids, limit to 15 as thats how many we can run in a single query\n","#also need to query the activities we have written to segment storage, so as not to repeat \n","#Strava API usage is limited on a per-application basis using both a 15-minute and daily request limit. The default rate limit allows 100 requests every 15 minutes, \n","# with up to 1,000 requests per day.\n","\n","#compare current activites vs what is written, \n","#going to need to write some try and excepts for expecting these values in return "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"Query_Segments","notebookOrigID":1439106573975145,"widgets":{}},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"89bbb57337a288069efe3ede2e44e349d48d03d33172adbe5738fcfdbda01bd0"}}},"nbformat":4,"nbformat_minor":0}
