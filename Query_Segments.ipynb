{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%run config"]},{"cell_type":"markdown","metadata":{},"source":["### API Query to get more specific details for each activity, need to pass each activity off individually "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["full_activity_dataset = spark.read.format(\"delta\").load(historical_activity_id_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"920f4af1-ce5f-48a7-8372-4725ed606ca0","showTitle":false,"title":""}},"outputs":[],"source":["#grab all of the disinct activity IDs \n","full_activity_ids = full_activity_dataset.select('activity_ids').distinct().rdd.flatMap(lambda x: x).collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#test before API call, so we'll see what is in storage first.\n","#see what happens if we don't have a datset to write \n","segmget_historical_dataset("]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["subset = full_activity_ids[:30]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def query_segments(activity_ids):\n","    import pandas as pd\n","        #can get the invdividal activites\n","    dataframe = pd.DataFrame()\n","    for id in activity_ids:\n","        activity_id_urls = (\"{}{}?include_all_efforts= True\").format(\"https://www.strava.com/api/v3/activities/\",id)\n","        header = {'Authorization': 'Bearer ' + access_token}\n","        param = {'per_page': 200, 'page': 1}\n","        my_activity = requests.get(activity_id_urls, headers=header, params=param).json()\n","\n","        segment_effort_count =  len(my_activity['segment_efforts'])\n","        count = 0\n","        activity_id_list =[]\n","        segment_id_list =[]\n","        while count < segment_effort_count:\n","\n","            activity_id = my_activity['segment_efforts'][count]['activity']['id']\n","            segment_id = my_activity['segment_efforts'][count]['id']\n","            activity_id_list.append(activity_id)\n","            segment_id_list.append(segment_id)\n","\n","            count += 1 \n","        \n","        columns = ['segment_id', 'activity_id']\n","        extracted_data = [segment_id_list, activity_id_list]\n","        segment_df = pd.DataFrame.from_dict(dict(zip(columns, extracted_data)))\n","\n","        dataframe.append(segment_df)\n","\n","    #convert pandas df to spark\n","        \n","    segment_spark_df = spark.createDataFrame(dataframe)\n","\n","    segment_spark_df = segment_spark_df.withColumn(\"ingest_file_name\", lit(\"activity_information\")) \\\n","                                .withColumn(\"ingested_at\", lit(current_timestamp()))\n","\n","    return segment_spark_df\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def query_segments_test(activity_ids):\n","    import pandas as pd\n","        #can get the invdividal activites\n","    dataframe = pd.DataFrame()\n","    for id in activity_ids:\n","        activity_id_urls = (\"{}{}?include_all_efforts= True\").format(\"https://www.strava.com/api/v3/activities/\",id)\n","        header = {'Authorization': 'Bearer ' + access_token}\n","        param = {'per_page': 200, 'page': 1}\n","        my_activity = requests.get(activity_id_urls, headers=header, params=param).json()\n","\n","        segment_effort_count =  len(my_activity['segment_efforts'])\n","        count = 0\n","        activity_id_list =[]\n","        segment_id_list =[]\n","        while count < segment_effort_count:\n","\n","            activity_id = my_activity['segment_efforts'][count]['activity']['id']\n","            segment_id = my_activity['segment_efforts'][count]['id']\n","            activity_id_list.append(activity_id)\n","            segment_id_list.append(segment_id)\n","                   \n","            columns = ['segment_id', 'activity_id']\n","            extracted_data = [segment_id_list, activity_id_list]\n","            segment_df = pd.DataFrame.from_dict(dict(zip(columns, extracted_data)))\n","            \n","            df = dataframe.append(segment_df)\n","            count += 1 \n","\n","    #convert pandas df to spark\n","\n","\n","    return df\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["subset = full_activity_ids[70:76]\n","pleasework=  query_segments_test(subset)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["subset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["testing_dataframe = pd.DataFrame()\n","activity_list = []\n","subset = full_activity_ids[25:30]\n","count = 0\n","import pandas as pd\n","for id in subset:\n","    activity_id_urls = (\"{}{}?include_all_efforts= True\").format(\"https://www.strava.com/api/v3/activities/\",id)\n","    header = {'Authorization': 'Bearer ' + access_token}\n","    param = {'per_page': 200, 'page': 1}\n","    my_activity = requests.get(activity_id_urls, headers=header, params=param).json()\n","    activity_id = my_activity['segment_efforts'][count]['activity']['id']\n","    column = [\"pleasework\"]\n","    extracted_data = [activity_id]\n","    dict_to_pass = dict(zip(column, extracted_data))\n","    pdf = pd.DataFrame.from_dict(data = dict_to_pass, orient= 'index', columns= column)\n","    testing_dataframe.append(pdf)\n","    count += 1\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["count = 0\n","for i in range(len([1,2,4])):\n","    print(count)\n","    count += 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pdf = pd.DataFrame.from_dict(dict_to_pass, orient='index', columns = column)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pdf"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["my_activity"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in subset:\n","    print(i)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pleasework"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pleasework['activity_id'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from distutils.log import error\n","segment_effort_path\n","\n","try:\n","    historical_dataframe = spark.read.format(\"delta\").load(segment_effort_path)\n","except:\n","    error\n","\n","if (historical_dataframe.count() > 0):\n","    return historical_dataframe\n","else:\n","    \n","\n","\n","return dataset "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","try:\n","    #try to read from storage\n","    pd.read_csv('file.csv')\n","except:\n","    #print(\"No file\") \n","    try: \n","        pd.read_csv('file.csv')\n","    except:\n","        print( \"No File x2\")\n","finally:\n","    print(\"1+1\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","try:\n","    #try to read from storage\n","    pd.read_csv('file.csv')\n","except: \n","    try:\n","    #if that fails, write the current dataframe to storage\n","        write_dataframe_to_storage(historical_df_to_write,storagepath, \"mergeSchema\", \"append\" )\n","    except:\n","        print(\"No Dataframe\")\n","    finally:\n","        historical_dataframe = spark.read.format(\"delta\").load(storagepath)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#run activites through api call\n","\n","#"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#need to get distinct activity_ids and run them through the segment\n","#we make 1 api query in the first script, so gonna be allowed 99 with this run "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#get all of the activity_ids, limit to 15 as thats how many we can run in a single query\n","#also need to query the activities we have written to segment storage, so as not to repeat \n","#Strava API usage is limited on a per-application basis using both a 15-minute and daily request limit. The default rate limit allows 100 requests every 15 minutes, \n","# with up to 1,000 requests per day.\n","\n","#compare current activites vs what is written, \n","#going to need to write some try and excepts for expecting these values in return "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"Query_Segments","notebookOrigID":1439106573975145,"widgets":{}},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"89bbb57337a288069efe3ede2e44e349d48d03d33172adbe5738fcfdbda01bd0"}}},"nbformat":4,"nbformat_minor":0}
