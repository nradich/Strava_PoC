{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PoC to pull data from the Strava API, and utilize DataBricks lakehouse for storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boto import config\n",
    "import requests\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "auth_url = \"https://www.strava.com/oauth/token\"\n",
    "activites_url = \"https://www.strava.com/api/v3/athlete/activities\"\n",
    "\n",
    "\n",
    "payload = {\n",
    "    'client_id':  client_id,\n",
    "    'client_secret': client_secret,\n",
    "    'code': authorization_code,\n",
    "    'grant_type': 'authorization_code',\n",
    "    'f': 'json'\n",
    "}\n",
    "\n",
    "print(\"Requesting Token...\\n\")\n",
    "res = requests.post(auth_url, data=payload, verify=False)\n",
    "refresh_token = res.json()['refresh_token']\n",
    "access_token = res.json()['access_token']\n",
    "expire_at_unix_time = res.json()['expires_at']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API call to grab all of the acitivites within a personal account\n",
    "activites_url = \"https://www.strava.com/api/v3/athlete/activities\"\n",
    "header = {'Authorization': 'Bearer ' + access_token}\n",
    "param = {'per_page': 200, 'page': 1}\n",
    "my_dataset = requests.get(activites_url, headers=header, params=param).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all of the activity ids from the bigger dataset\n",
    "activity_ids = []\n",
    "count = 0\n",
    "while count < len(my_dataset):\n",
    "    activity_ids.append(my_dataset[count]['id'])\n",
    "    count += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can get the invdividal activites\n",
    "activity_id_urls = (\"{}{}?include_all_efforts= True\").format(\"https://www.strava.com/api/v3/activities/\",\"\")\n",
    "header = {'Authorization': 'Bearer ' + access_token}\n",
    "param = {'per_page': 200, 'page': 1}\n",
    "my_activity_ = requests.get(activity_id_urls, headers=header, params=param).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_activity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_activity_['segment_efforts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at the various segments within the particular activity \n",
    "my_activity_['segment_efforts'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segment effort API call \n",
    "segment_id_url =(\"{}{}\").format( \"https://www.strava.com/api/v3/segment_efforts/\",) \n",
    "header = {'Authorization': 'Bearer ' + access_token}\n",
    "param = {'per_page': 200, 'page': 1}\n",
    "my_segment_ = requests.get(segment_id_url, headers=header, params=param).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_segment_['segment']['id']\n",
    "#Some very interesting information in this one, oldest created date\n",
    "# 'effort_count': 20871,\n",
    " #'athlete_count': 1955,\n",
    " #'star_count': 11,\n",
    "segment_id_url =(\"{}{}\").format( \"https://www.strava.com/api/v3/segments/\",) \n",
    "header = {'Authorization': 'Bearer ' + access_token}\n",
    "param = {'per_page': 200, 'page': 1}\n",
    "my_segment = requests.get(segment_id_url, headers=header, params=param).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interesting Fields from Json segment \n",
    "name': '26th St.',\n",
    " 'activity_type': 'Ride',\n",
    " 'distance': 674.65,\n",
    "  'city': 'San Diego',\n",
    "\n",
    "\n",
    "\n",
    "   'athlete_segment_stats': {'pr_elapsed_time': 136,\n",
    "  'pr_date': '2022-04-29',\n",
    "  'pr_activity_id': 7062090532,\n",
    "  'effort_count': 18},\n",
    " 'xoms': {'kom': '45s',\n",
    "  'qom': '1:24',\n",
    "  'overall': '45s',\n",
    "\n",
    "\n",
    "   'effort_count': 20871,\n",
    " 'athlete_count': 1955,\n",
    " 'star_count': 11,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpful sparkcode from databricks cert\n",
    "\n",
    "from pyspark.sql.functions import * \n",
    "#read in 2017 files into dataframe\n",
    "df_2017 =spark.read.text(batch_2017_path)\n",
    "\n",
    "#extract columns and appropriate headers\n",
    "df_new = df_2017.withColumn('submitted_at',  col('value').substr(1,15)) \\\n",
    ".withColumn('order_id', col('value').substr(16,40))\\\n",
    ".withColumn('customer_id', col('value').substr(56,40))\\\n",
    ".withColumn('sales_rep_id', col('value').substr(96,40)) \\\n",
    ".withColumn('sales_rep_ssn', col('value').substr(136,15))\\\n",
    ".withColumn('sales_rep_first_name', col('value').substr(151,15))\\\n",
    ".withColumn('sales_rep_last_name', col('value').substr(166,15))\\\n",
    ".withColumn('sales_rep_address', col('value').substr(181,40))\\\n",
    ".withColumn('sales_rep_city', col('value').substr(221,20))\\\n",
    ".withColumn('sales_rep_state', col('value').substr(241,2))\\\n",
    ".withColumn('sales_rep_zip', col('value').substr(243,5))\\\n",
    ".withColumn('shipping_address_attention', col('value').substr(248,30))\\\n",
    ".withColumn('shipping_address_address', col('value').substr(278,40))\\\n",
    ".withColumn('shipping_address_city', col('value').substr(318,20))\\\n",
    ".withColumn('shipping_address_state', col('value').substr(338,2))\\\n",
    ".withColumn('shipping_address_zip', col('value').substr(340,5))\\\n",
    ".withColumn('product_id', col('value').substr(345,40))\\\n",
    ".withColumn('product_quantity', col('value').substr(385,5))\\\n",
    ".withColumn('product_sold_price', col('value').substr(390,20))\\\n",
    ".drop('value') \n",
    "\n",
    "\n",
    "df2 = df_new.select([trim(col(c)).alias(c) for c in df_new.columns]) \n",
    "df2= df2.select([when(col(c)== \"\", None).otherwise(col(c)).alias(c) for c in df2.columns])\n",
    "df_2 = df2.withColumn(\"ingest_file_name\", input_file_name()) \\\n",
    "        .withColumn(\"ingested_at\", current_timestamp())\n",
    "\n",
    "\n",
    "df_2.write.format(\"delta\")\\\n",
    ".option(\"overwriteSchema\", \"true\")\\\n",
    ".mode(\"overwrite\")\\\n",
    ".save(batch_target_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89bbb57337a288069efe3ede2e44e349d48d03d33172adbe5738fcfdbda01bd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
