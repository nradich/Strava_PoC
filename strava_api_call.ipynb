{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PoC to pull data from the Strava API, and utilize DataBricks lakehouse for storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#needed to grab authorization code INITIALLY\n",
    "#make sure to save refresh token !\n",
    "from boto import config\n",
    "import requests\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "auth_url = \"https://www.strava.com/oauth/token\"\n",
    "activites_url = \"https://www.strava.com/api/v3/athlete/activities\"\n",
    "\n",
    "\n",
    "payload = {\n",
    "    'client_id':  client_id,\n",
    "    'client_secret': client_secret,\n",
    "    'code': authorization_code,\n",
    "    'grant_type': 'authorization_code',\n",
    "    'f': 'json'\n",
    "}\n",
    "\n",
    "print(\"Requesting Token...\\n\")\n",
    "res = requests.post(auth_url, data=payload, verify=False)\n",
    "refresh_token = res.json()['refresh_token']\n",
    "access_token = res.json()['access_token']\n",
    "expire_at_unix_time = res.json()['expires_at']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can run this script multiple times with new refresh token\n",
    "from boto import config\n",
    "import requests\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "auth_url = \"https://www.strava.com/oauth/token\"\n",
    "activites_url = \"https://www.strava.com/api/v3/athlete/activities\"\n",
    "\n",
    "\n",
    "payload = {\n",
    "    'client_id':  client_id,\n",
    "    'client_secret': client_secret,\n",
    "    'refresh_token': new_refresh_token,\n",
    "    'grant_type': 'refresh_token',\n",
    "    'f': 'json'\n",
    "}\n",
    "\n",
    "res = requests.post(auth_url, data=payload, verify=False)\n",
    "refresh_token = res.json()['refresh_token']\n",
    "access_token = res.json()['access_token']\n",
    "expire_at_unix_time = res.json()['expires_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API call to grab all of the acitivites within a personal account\n",
    "activites_url = \"https://www.strava.com/api/v3/athlete/activities\"\n",
    "header = {'Authorization': 'Bearer ' + access_token}\n",
    "param = {'per_page': 200, 'page': 1}\n",
    "my_dataset = requests.get(activites_url, headers=header, params=param).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "df = spark.read.json(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all of the activity ids from the bigger dataset\n",
    "activity_ids = []\n",
    "count = 0\n",
    "while count < len(my_dataset):\n",
    "    activity_ids.append(my_dataset[count]['id'])\n",
    "    count += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_activity = activity_ids[15:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [x for x in activity_ids if x not in subset_activity ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(activity_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subset_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The activities url is the one I want to query, it is pertitent to my personal activities \n",
    "### Need to submit specific activity ID to get segment information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id = 7491632820\n",
    "my_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in activity_ids:\n",
    "    print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can get the invdividal activites\n",
    "activity_id_urls = (\"{}{}?include_all_efforts= True\").format(\"https://www.strava.com/api/v3/activities/\",7491632820)\n",
    "header = {'Authorization': 'Bearer ' + access_token}\n",
    "param = {'per_page': 200, 'page': 1}\n",
    "my_activity = requests.get(activity_id_urls, headers=header, params=param).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The distance is returned in meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_activity['segment_efforts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len (my_activity['segment_efforts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_activity['segment_efforts'][22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_effort_count =  len(my_activity['segment_efforts'])\n",
    "count = 0\n",
    "activity_id_list =[]\n",
    "segment_id_list =[]\n",
    "while count < segment_effort_count:\n",
    "\n",
    "    activity_id = my_activity['segment_efforts'][count]['activity']['id']\n",
    "    segment_id = my_activity['segment_efforts'][count]['id']\n",
    "\n",
    "    activity_id_list.append(activity_id)\n",
    "    segment_id_list.append(segment_id)\n",
    "\n",
    "    count += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_dict = dict(zip(activity_id_list,segment_id_list ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trial_dict:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in trial_dict.items():\n",
    "    print (item)\n",
    "    print(type(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len (activity_id_list))\n",
    "print(len (segment_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['segment_id', 'activity_id']\n",
    "extracted_data = [segment_id_list, activity_id_list]\n",
    "trial_df = pd.DataFrame.from_dict(dict(zip(columns, extracted_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_segment = [segment_id_list]\n",
    "testing = dict(zip([\"segment_id\"], list_of_segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testing.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count =0\n",
    "for i in testing.values():\n",
    "    print(count)\n",
    "count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in new_dict:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in len(activity_id_list):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_activity_dict = {segment_id_list[i]: activity_id_list[i] for i in range(len(activity_id_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {\"segment_id\", 1:\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_list_of_list = [segment_id_list, activity_id_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['segment_id', 'activity_id']\n",
    "test = pd.DataFrame(trial_list_of_list, orient = 'index' ,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trial_list_of_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_dict = {\"segment_id\" ,segment_id_list}\n",
    "\n",
    "data= pd.DataFrame.from_dict(segment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_activity_dict.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data= pd.DataFrame.from_dict(segment_activity_dict, columns= ['segment_id', 'acitivty_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_effort_count =  len(my_activity['segment_efforts'])\n",
    "count = 0\n",
    "while count < segment_effort_count:\n",
    "    print(my_activity['segment_efforts'][count]['activity']['id'])\n",
    "    print(my_activity['segment_efforts'][count]['id'])\n",
    "\n",
    "    count += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_activity['segment_efforts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(segment_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while i < len(my_activity['segment_efforts']):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_activity['segment_efforts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#breaking it out...\n",
    "my_activity['segment_efforts']['id']\n",
    "my_activity['segment_efforts']['activity']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_id = my_activity['segment_efforts'][1]['activity']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are two ids \n",
    "#defintiely the longer one for segment_efforts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_activity['segment_efforts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_activity_['distance']\n",
    "moving_time\n",
    "elapsed_time\n",
    "'type'\n",
    "'average_speed'\n",
    "'segment_efforts'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segment effort API call \n",
    "segment_id_url =(\"{}{}\").format( \"https://www.strava.com/api/v3/segment_efforts/\",\"\") \n",
    "header = {'Authorization': 'Bearer ' + access_token}\n",
    "param = {'per_page': 200, 'page': 1}\n",
    "my_segment_ = requests.get(segment_id_url, headers=header, params=param).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of segments within a particular activity \n",
    "len(my_activity_['segment_efforts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segment effort API call \n",
    "segment_id_url =(\"{}{}\").format( \"https://www.strava.com/api/v3/segment_efforts/\",\"\") \n",
    "header = {'Authorization': 'Bearer ' + access_token}\n",
    "param = {'per_page': 200, 'page': 1}\n",
    "my_segment_2984285855829947126 = requests.get(segment_id_url, headers=header, params=param).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_segment_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {'Authorization': 'Bearer ' + access_token}\n",
    "param = {'per_page': 200, 'page': 1}\n",
    "my_segment = requests.get(segment_id_url, headers=header, params=param).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_segment_['segment']['id']\n",
    "#Some very interesting information in this one, oldest created date\n",
    "# 'effort_count': 20871,\n",
    " #'athlete_count': 1955,\n",
    " #'star_count': 11,\n",
    "segment_id_url =(\"{}{}\").format( \"https://www.strava.com/api/v3/segments/\",) \n",
    "header = {'Authorization': 'Bearer ' + access_token}\n",
    "param = {'per_page': 200, 'page': 1}\n",
    "my_segment = requests.get(segment_id_url, headers=header, params=param).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interesting Fields from Json segment \n",
    "name': '26th St.',\n",
    " 'activity_type': 'Ride',\n",
    " 'distance': 674.65,\n",
    "  'city': 'San Diego',\n",
    "\n",
    "\n",
    "\n",
    "   'athlete_segment_stats': {'pr_elapsed_time': 136,\n",
    "  'pr_date': '2022-04-29',\n",
    "  'pr_activity_id': 7062090532,\n",
    "  'effort_count': 18},\n",
    " 'xoms': {'kom': '45s',\n",
    "  'qom': '1:24',\n",
    "  'overall': '45s',\n",
    "\n",
    "\n",
    "   'effort_count': 20871,\n",
    " 'athlete_count': 1955,\n",
    " 'star_count': 11,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpful sparkcode from databricks cert\n",
    "\n",
    "from pyspark.sql.functions import * \n",
    "#read in 2017 files into dataframe\n",
    "df_2017 =spark.read.text(batch_2017_path)\n",
    "\n",
    "#extract columns and appropriate headers\n",
    "df_new = df_2017.withColumn('submitted_at',  col('value').substr(1,15)) \\\n",
    ".withColumn('order_id', col('value').substr(16,40))\\\n",
    ".withColumn('customer_id', col('value').substr(56,40))\\\n",
    ".withColumn('sales_rep_id', col('value').substr(96,40)) \\\n",
    ".withColumn('sales_rep_ssn', col('value').substr(136,15))\\\n",
    ".withColumn('sales_rep_first_name', col('value').substr(151,15))\\\n",
    ".withColumn('sales_rep_last_name', col('value').substr(166,15))\\\n",
    ".withColumn('sales_rep_address', col('value').substr(181,40))\\\n",
    ".withColumn('sales_rep_city', col('value').substr(221,20))\\\n",
    ".withColumn('sales_rep_state', col('value').substr(241,2))\\\n",
    ".withColumn('sales_rep_zip', col('value').substr(243,5))\\\n",
    ".withColumn('shipping_address_attention', col('value').substr(248,30))\\\n",
    ".withColumn('shipping_address_address', col('value').substr(278,40))\\\n",
    ".withColumn('shipping_address_city', col('value').substr(318,20))\\\n",
    ".withColumn('shipping_address_state', col('value').substr(338,2))\\\n",
    ".withColumn('shipping_address_zip', col('value').substr(340,5))\\\n",
    ".withColumn('product_id', col('value').substr(345,40))\\\n",
    ".withColumn('product_quantity', col('value').substr(385,5))\\\n",
    ".withColumn('product_sold_price', col('value').substr(390,20))\\\n",
    ".drop('value') \n",
    "\n",
    "\n",
    "df2 = df_new.select([trim(col(c)).alias(c) for c in df_new.columns]) \n",
    "df2= df2.select([when(col(c)== \"\", None).otherwise(col(c)).alias(c) for c in df2.columns])\n",
    "df_2 = df2.withColumn(\"ingest_file_name\", input_file_name()) \\\n",
    "        .withColumn(\"ingested_at\", current_timestamp())\n",
    "\n",
    "\n",
    "df_2.write.format(\"delta\")\\\n",
    ".option(\"overwriteSchema\", \"true\")\\\n",
    ".mode(\"overwrite\")\\\n",
    ".save(batch_target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataBricks Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /config\n",
    "\n",
    "\n",
    "#API call to grab all of the acitivites within a personal account\n",
    "def activity_api_call(access_token):\n",
    "    activites_url = \"https://www.strava.com/api/v3/athlete/activities\"\n",
    "    header = {'Authorization': 'Bearer ' + access_token}\n",
    "    param = {'per_page': 200, 'page': 1}\n",
    "    activity_dataset = requests.get(activites_url, headers=header, params=param).json()\n",
    "    \n",
    "    return activity_dataset\n",
    "\n",
    "my_dataset = activity_api_call(access_token)\n",
    "\n",
    "\n",
    "\n",
    "#get all of the activity ids from the bigger dataset\n",
    "#xtract all of the columns we want\n",
    "def extract_activities(dataset):\n",
    "    \"\"\"Function to seperate activity_ids and create an activity dataframe. Returns 2 \"\"\"\n",
    "    activity_ids = []\n",
    "    start_date = []\n",
    "    activity_name =[]\n",
    "    distance = []\n",
    "    moving_time = []\n",
    "    elapsed_time = []\n",
    "    sport_type = []\n",
    "    total_elevation_gain =[]\n",
    "    count = 0\n",
    "    while count < len(my_dataset):\n",
    "        activity_ids.append(dataset[count]['id'])\n",
    "        start_date.append(dataset[count]['start_date'])\n",
    "        activity_name.append(dataset[count]['name'])\n",
    "        distance.append(dataset[count]['distance'])\n",
    "        moving_time.append(dataset[count]['moving_time'])\n",
    "        elapsed_time.append(dataset[count]['elapsed_time'])\n",
    "        sport_type.append(dataset[count]['sport_type'])\n",
    "        total_elevation_gain.append(dataset[count]['total_elevation_gain'])\n",
    "        count += 1 \n",
    "        \n",
    "    #convert list to dataframe   \n",
    "    from pyspark.sql.types import LongType\n",
    "    activity_id_DF = spark.createDataFrame(activity_ids, LongType())\n",
    "    activity_id_DF = activity_id_DF.withColumnRenamed('value', 'activity_id')\n",
    "    \n",
    "    #columns names for initial DF\n",
    "    #need to specify schema\n",
    "    columns = ['activity_ids','start_date', 'activity_name', 'distance', 'moving_time','elapsed_time', 'sport_type'\\\n",
    "          ,'total_elevation_gain']\n",
    "    #list of lists\n",
    "    extracted_data = [activity_ids,start_date, activity_name, distance, moving_time,elapsed_time, sport_type\\\n",
    "          ,total_elevation_gain]\n",
    "\n",
    "    import pandas as pd\n",
    "    #create a pandas Dataframe, then convert to spark to write to storage\n",
    "    pdf = pd.DataFrame.from_dict(dict(zip(columns, extracted_data)))\n",
    "    activity_df = spark.createDataFrame(pdf)\n",
    "\n",
    "    return activity_id_DF, activity_df\n",
    "\n",
    "\n",
    "\n",
    "activity_id_DF, activity_df = extract_activities(my_dataset)\n",
    "\n",
    "from pyspark.sql.types import LongType\n",
    "#convert list to sparkdataframes\n",
    "activity_id_DF = spark.createDataFrame(activity_ids, LongType())\n",
    "activity_id_DF = activity_id_DF.withColumnRenamed('value', 'activity_id')\n",
    "\n",
    "\n",
    "#write the activity ids to storage, overwrite the previous iteration\n",
    "activity_id_DF,activity_id_path\n",
    "def write_activity_ids_to_storage(dataset, storage_path):\n",
    "    \"\"\"Function to write activity ids to storage. Will overwrite current delta file in storage\"\"\"\n",
    "    dataset.write.format(\"delta\")\\\n",
    "    .option(\"overwriteSchema\", \"true\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save(storage_path)\n",
    "\n",
    "write_activity_ids_to_storage(activity_id_DF,activity_id_path)\n",
    "#read the activities from storage\n",
    "stored_activity_ids = spark.read.format(\"delta\").load(activity_id_path)\n",
    "\n",
    "\n",
    "#read in historical activity IDS to compare\n",
    "#trying to compare current query vs historical, if nothing is written to storage ie first run, still need to execute and write original DF to storage\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "try:\n",
    "    historical_activity_ids = spark.read.format(\"delta\").load(historical_activity_id_path)\n",
    "except: \n",
    "    AnalysisException, NameError\n",
    "else:\n",
    "    write_activity_df_to_storage()\n",
    "else:\n",
    "    new_activity_ids = [x for x in activity_id_DF if x not in historical_activity_ids ]\n",
    "#compare historical vs recent query,\n",
    "#will then need to keep it under 15 until len(new_activity_ids) =0 \n",
    "\n",
    "\n",
    "#columns names for initial DF\n",
    "#need to specify schema\n",
    "columns = ['activity_ids','start_date', 'activity_name', 'distance', 'moving_time','elapsed_time', 'sport_type'\\\n",
    "          ,'total_elevation_gain']\n",
    "#list of lists\n",
    "extracted_data = [activity_ids,start_date, activity_name, distance, moving_time,elapsed_time, sport_type\\\n",
    "          ,total_elevation_gain]\n",
    "\n",
    "import pandas as pd\n",
    "#create a pandas Dataframe, then convert to spark to write to storage\n",
    "pdf = pd.DataFrame.from_dict(dict(zip(columns, extracted_data)))\n",
    "activity_df = spark.createDataFrame(pdf)\n",
    "\n",
    "#write the activity ids to storage, overwrite the previous iteration\n",
    "\n",
    "activity_id_DF.write.format(\"delta\")\\\n",
    ".option(\"overwriteSchema\", \"true\")\\\n",
    ".mode(\"overwrite\")\\\n",
    ".save(historical_activity_id_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89bbb57337a288069efe3ede2e44e349d48d03d33172adbe5738fcfdbda01bd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
